{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import datetime\n",
    "\n",
    "pd.options.display.max_columns = 8\n",
    "pd.options.display.max_rows = 50\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "SOURCE_PATH = '../data/source/'\n",
    "SUBMISSION_PATH = '../data/submission/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_cardinality(data, feature):\n",
    "    data[feature].fillna('nan', inplace=1)\n",
    "    feature_dict = dict(data[feature].value_counts(dropna=False))\n",
    "    data[feature] = data[feature].map(lambda x: feature_dict[x])\n",
    "    return data\n",
    "\n",
    "def parse_date(date, target='year'):\n",
    "    if hasattr(date, target):\n",
    "        return getattr(date, target)\n",
    "    elif type(date) is str:\n",
    "        if len(date.split(' ')[0].split('/')) == 3:\n",
    "            if target == 'year':\n",
    "                return int(date.split(' ')[0].split('/')[2])\n",
    "            elif target == 'month':\n",
    "                return int(date.split(' ')[0].split('/')[0])\n",
    "        else:\n",
    "            return np.nan\n",
    "        \n",
    "def one_hot_encode(data, features):\n",
    "    le = LabelEncoder()\n",
    "    onehot = OneHotEncoder(sparse=False)\n",
    "    for feature in features:\n",
    "        data[feature] = le.fit_transform(data[feature])\n",
    "        labels = le.classes_\n",
    "        hot = onehot.fit_transform(np.array(data[[feature]]))\n",
    "        temp = pd.DataFrame(hot, columns=[feature + '_' + str(label) for label in labels])\n",
    "        if data[feature].dtype == object:\n",
    "            data.drop(feature, axis=1, inplace=True)\n",
    "        data = data.merge(temp, left_index=True, right_index=True)\n",
    "        data.drop(feature, axis=1, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_excel(os.path.join(SOURCE_PATH, 'train.xlsx'), sheetname=1, encoding='utf-8')\n",
    "test = pd.read_excel(os.path.join(SOURCE_PATH, 'test.xlsx'), sheetname=1, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['is_train'] = 1\n",
    "test['is_train'] = 0\n",
    "data = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['target'] = data['OPPORTUNITY STAGENAME'].map(lambda x: int(x == 'Closed Won'))\n",
    "if data.filter(like='OPP').shape[1] > 0:\n",
    "    data.drop(train.filter(like='OPP').columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useless features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drop_features = ['EMAIL', 'CONTACT QUALIFICATION', 'CONTACT.QUALIFIEDDATE__C', 'COMAPNYNAME']\n",
    "for feature in drop_features:\n",
    "    if feature in data.columns:\n",
    "        data.drop(feature, axis=1, inplace=True)\n",
    "    else: print \"ERROR, no such feature\", feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add nan features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nan_features = ['zip_set', 'State', 'PRODUCTLIST__C']\n",
    "for feature in nan_features:\n",
    "    if feature in data.columns:\n",
    "        data[feature+'_isnan'] = data[feature].isnull().astype(int)\n",
    "    else: print \"ERROR, no such feature\", feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cardinality encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "card_features = ['zip_set', 'State', 'PRODUCTLIST__C', 'CAMPAIGN.CAMPAIGN_CODE__C', 'CAMPAIGN.NAME', \n",
    "                 'CAMPAIGN.SUB_TYPE__C', 'ACTIVITY FILENAME__C', 'ACTIVITY_NAME']\n",
    "for feature in card_features:\n",
    "    if feature in data.columns:\n",
    "        data = encode_cardinality(data, feature)\n",
    "    else: print \"ERROR, no such feature\", feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "onehot_features = ['RECORD-TYPE', 'CAMPAIGN.TYPE', 'CAMPAIGN_DEPARTMENT']\n",
    "data = one_hot_encode(data, onehot_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special features processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 'RECORD_CREATEDDATE' in data.columns:\n",
    "    data['rec_cd_month'] = data.RECORD_CREATEDDATE.map(lambda x: x.month)\n",
    "    data.rec_cd_month.fillna(-1, inplace=True)\n",
    "    data.drop('RECORD_CREATEDDATE', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 'LEAD_CONTACT_CREATEDDATE' in data.columns:\n",
    "    data['lc_cd_month'] = data.LEAD_CONTACT_CREATEDDATE.map(lambda x: parse_date(x, target='month'))\n",
    "    data['lc_cd_year'] = data.LEAD_CONTACT_CREATEDDATE.map(lambda x: parse_date(x, target='year'))\n",
    "    data.drop('LEAD_CONTACT_CREATEDDATE', axis=1, inplace=True)\n",
    "data.lc_cd_month.fillna(-1, inplace=True)\n",
    "data.lc_cd_year.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 'CREATEDBYID' in data.columns:\n",
    "    data['cr_byid_7MY1AAM'] = (data.CREATEDBYID == '005600000017MY1AAM').astype(int)\n",
    "    data['cr_byid_VxfoAAC'] = (data.CREATEDBYID == '00560000001VxfoAAC').astype(int)\n",
    "    data['cr_byid_other'] = ((data.CREATEDBYID != '00560000001VxfoAAC') & (data.CREATEDBYID != '005600000017MY1AAM')).astype(int)\n",
    "    data.drop('CREATEDBYID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 'COUNTRY' in data.columns:\n",
    "    data['is_Germany'] = (data.COUNTRY == 'Germany').astype(int)\n",
    "    data['is_USA'] = (data.COUNTRY == 'United States').astype(int)\n",
    "    data['country_isnan'] = data.COUNTRY.isnull().astype(int)\n",
    "    data['country_other'] = ((data.COUNTRY.notnull()) & (data.COUNTRY != 'Germany') & (data.COUNTRY != 'United States')).astype(int)\n",
    "    data.drop('COUNTRY', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 'ACTIVITY_TYPE__C' in data.columns:\n",
    "    top = ['Registration', 'License Generation', 'Download', 'Download resource'] \n",
    "    data['act_na'] = data.ACTIVITY_TYPE__C.isnull().astype(int)\n",
    "    data['act_registration'] = (data.ACTIVITY_TYPE__C == 'Registration').astype(int)\n",
    "    data['act_license'] = (data.ACTIVITY_TYPE__C == 'License Generation').astype(int)\n",
    "    data['act_download'] = (data.ACTIVITY_TYPE__C == 'Download').astype(int)\n",
    "    data['act_download_res'] = (data.ACTIVITY_TYPE__C == 'Download resource').astype(int)\n",
    "    data['act_other'] = ((data.ACTIVITY_TYPE__C.notnull()) & \n",
    "                         (data.ACTIVITY_TYPE__C.map(lambda x: x not in top))\n",
    "                        ).astype(int)\n",
    "    data.drop('ACTIVITY_TYPE__C', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping by domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "main_data = data.groupby('DOMAIN').mean()\n",
    "data['e_count'] = np.ones((data['DOMAIN'].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Email_counts feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e_count = data[['DOMAIN', 'e_count']].groupby('DOMAIN').count()\n",
    "main_data = main_data.merge(e_count, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22718, 53) (22357, 53)\n",
      "(22718, 51) (22357, 51) (22718,) (22357,)\n"
     ]
    }
   ],
   "source": [
    "train = main_data[main_data.is_train == 1]\n",
    "test = main_data[main_data.is_train == 0]\n",
    "print train.shape, test.shape\n",
    "\n",
    "x_train = np.array(train.drop(['target', 'is_train'], axis=1))\n",
    "y_train = np.array(train.target)\n",
    "x_test = np.array(test.drop(['target', 'is_train'], axis=1))\n",
    "y_test = np.array(test.target)\n",
    "print x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "model = xgb.XGBClassifier(max_depth=4, learning_rate=0.02, n_estimators=600,\n",
    "                          silent=1, objective=\"binary:logistic\", min_child_weight=5, seed=42)\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict_proba(x_test)[:, 1]\n",
    "submisson = pd.DataFrame({'is_Closed_Won_prob':y_pred}, index=test.index)\n",
    "submisson.to_csv(os.path.join(SUBMISSION_PATH, 'veeam_results2.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
