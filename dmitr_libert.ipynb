{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn import cross_validation\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import  RandomForestRegressor,RandomForestClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_gini(preds, dtrain):\n",
    "    true = dtrain.get_label()    \n",
    "    gini = Gini(true, preds)\n",
    "    gini *= -1\n",
    "    return 'gini', gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(data, features):\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        onehot = OneHotEncoder(sparse=False)\n",
    "        data[feature] = le.fit_transform(data[feature])\n",
    "        labels = le.classes_\n",
    "        hot = onehot.fit_transform(np.array(data[[feature]]))\n",
    "        temp = pd.DataFrame(hot, columns=[feature + '_' + str(label) for label in labels],index = data[feature].index)\n",
    "        if data[feature].dtype == object:\n",
    "            data.drop(feature, axis=1, inplace=True)\n",
    "        data = pd.concat([data,temp],axis =1,join_axes=[data.index])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Gini(y_true, y_pred):\n",
    "    # check and get number of samples\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    n_samples = y_true.shape[0]\n",
    "    \n",
    "    # sort rows on prediction column \n",
    "    # (from largest to smallest)\n",
    "    arr = np.array([y_true, y_pred]).transpose()\n",
    "    true_order = arr[arr[:,0].argsort()][::-1,0]\n",
    "    pred_order = arr[arr[:,1].argsort()][::-1,0]\n",
    "    \n",
    "    \n",
    "    # get Lorenz curves\n",
    "    L_true = np.cumsum(true_order) / np.sum(true_order)\n",
    "    L_pred = np.cumsum(pred_order) / np.sum(pred_order)\n",
    "    L_ones = np.linspace(0, 1, n_samples)\n",
    "    \n",
    "    # get Gini coefficients (area between curves)\n",
    "    G_true = np.sum(L_ones - L_true)\n",
    "    G_pred = np.sum(L_ones - L_pred)\n",
    "    \n",
    "    # normalize to true Gini coefficient\n",
    "    return G_pred/G_true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgboost_pred_without_offset(train,labels,test):\n",
    "    params = {}\n",
    "    params[\"objective\"] = \"count:poisson\"\n",
    "    params[\"eta\"] = 0.005\n",
    "    params[\"min_child_weight\"] = 6\n",
    "    params[\"subsample\"] = 0.7\n",
    "    params[\"colsample_bytree\"] = 1\n",
    "    params[\"scale_pos_weight\"] = 1\n",
    "    params[\"silent\"] = 1\n",
    "    params[\"max_depth\"] = 6\n",
    "    params[\"seed\"] = 42\n",
    "\n",
    "    plst = list(params.items())\n",
    "\n",
    "    num_rounds = 1800\n",
    "    xgtest = xgb.DMatrix(test)\n",
    "\n",
    "    #create a train and validation dmatrices \n",
    "    xgtrain = xgb.DMatrix(train, label=labels)\n",
    "\n",
    "    model = xgb.train(plst, xgtrain, num_rounds)\n",
    "    preds = model.predict(xgtest)\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ensemble(X_train, y_train, X_test):\n",
    "    threshold = 3\n",
    "    y_binar = binar_xgboost_pred(X_train,y_train<=threshold,X_test)\n",
    "\n",
    "    n_of_chunks = 5\n",
    "    kf = cross_validation.KFold(len(X_train), n_of_chunks, random_state = 7)\n",
    "    y_pred = np.zeros(len(X_test))\n",
    "    for train_index, test_index in kf:\n",
    "        y_pred += xgboost_pred_without_offset(X_train[train_index],y_train[train_index],X_test)\n",
    "        \n",
    "\n",
    "    y_pred = y_pred - y_binar*n_of_chunks*1.5\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binar_xgboost_pred(X_train,y_train,X_test):\n",
    "    param = {'objective':'binary:logistic' ,'eta':0.1, 'max_depth':2,'silent':1,\n",
    "    'min_child_weight':25, 'scale_pos_weight':1.0, 'subsample':0.7, 'colsample_bytree':1}\n",
    "    param['booster'] = 'gbtree'\n",
    "    plst = list(param.items())\n",
    "    num_rounds = 800\n",
    "    xgtest = xgb.DMatrix(X_test)\n",
    "    #labels = (y_train >= lb)*(y_train <= rb)\n",
    "    xgtrain = xgb.DMatrix(X_train, label = y_train)\n",
    "    model = xgb.train(plst, xgtrain, num_rounds)\n",
    "    y_pred = model.predict(xgtest)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_val(X,y,n_folds = 3):\n",
    "    n_elems = len(X)\n",
    "    kf = cross_validation.KFold(n_elems, n_folds)\n",
    "    predictions = []\n",
    "    answers = []\n",
    "    for train_index, test_index in kf:\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        y_pred = ensemble(X_train, y_train, X_test)\n",
    "        predictions.extend(y_pred)\n",
    "        answers.extend(y_test)\n",
    "    return Gini(np.array(answers), np.array(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_load  = pd.read_csv('train.csv', index_col=0)\n",
    "test_load  = pd.read_csv('test.csv', index_col=0)\n",
    "\n",
    "labels = train_load.Hazard\n",
    "train_load.drop('Hazard', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_s = train_load.copy()\n",
    "test_s = test_load.copy()\n",
    "\n",
    "\n",
    "columns = train_load.columns\n",
    "test_ind = test_load.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data = train_s.copy()\n",
    "train_load['is_train'] = 1\n",
    "test_load['is_train'] = 0\n",
    "data = pd.concat([train_load, test_load]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat_features = ['T1_V4','T1_V5','T1_V6','T1_V7','T1_V8','T1_V9','T1_V11',\n",
    "                'T1_V12','T1_V15','T1_V16','T1_V17','T2_V3','T2_V5','T2_V11','T2_V12','T2_V13']\n",
    "data = one_hot_encode(data, cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drop_features = ['T1_V15_N','T1_V16_I', 'T2_V12', 'T1_V12', 'T2_V5_D', 'T2_V3', 'T1_V4_G', 'T2_V5_C', 'T1_V16_D', 'T1_V11_M', \n",
    " 'T1_V4_E', 'T1_V11_D', 'T1_V6', 'T1_V16_O', 'T1_V5_D', 'T1_V11_K', 'T1_V16_M', 'T1_V16_N', 'T1_V5_H', \n",
    " 'T1_V15_H', 'T1_V15_D', 'T2_V7', 'T2_V13_D', 'T1_V9_D', 'T1_V16_Q', 'T1_V4_S', 'T2_V13_C', 'T2_V5_E', 'T1_V16_L', \n",
    " 'T1_V11_F', 'T1_V16_G', 'T2_V3_N',  'T1_V15_A', 'T2_V5_B', 'T2_V13_E', 'T2_V5_A', 'T1_V15_W', 'T2_V3_Y',\n",
    " 'T1_V16_A', 'T1_V16_B', 'T2_V12_N', 'T2_V11_Y', 'T1_V17_Y', 'T2_V13_B', 'T2_V13_A', 'T2_V12_Y', 'T1_V17_N', 'T2_V5_F', \n",
    " 'T1_V16_R', 'T2_V11_N', 'T1_V15_C', 'T1_V11_A', 'T1_V12_D', 'T1_V9_C', 'T1_V8_D', 'T1_V8_B', 'T1_V12_B', 'T1_V7_D',\n",
    " 'T1_V7_B', 'T1_V7_A', 'T1_V6_Y', 'T1_V6_N', 'T1_V5_L', 'T1_V5_E', 'T1_V5_B', 'T1_V5_A', 'T1_V4_W', 'T1_V4_C', 'T1_V4_B', \n",
    " 'T1_V9_B', 'T1_V8_A', 'T1_V9_G', 'T1_V11_B', 'T1_V11_N', 'T1_V12_A', 'T1_V5_J', 'T1_V5_C', 'T2_V10', 'T1_V15_S', 'T1_V11_H',\n",
    " 'T1_V16_C', 'T1_V16_H', 'T1_V9_F', 'T1_V8', 'T1_V16_E', 'T1_V16_J', 'T1_V15_F', 'T1_V11_L', 'T1_V5_I',\n",
    " 'T1_V16_F', 'T1_V5_K', 'T1_V9_E', 'T1_V11_I', 'T1_V11_J', 'T1_V13', 'T1_V10', 'T1_V7', 'T1_V16_K']\n",
    "\n",
    "\n",
    "for feat in drop_features:\n",
    "    data.drop(feat,axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\algomost\\Anaconda\\lib\\site-packages\\IPython\\kernel\\__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\algomost\\Anaconda\\lib\\site-packages\\IPython\\kernel\\__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "train = data[data['is_train'] == 1]\n",
    "test = data[data['is_train'] == 0]\n",
    "train.drop('is_train',axis=1, inplace=True)\n",
    "test.drop('is_train',axis=1, inplace=True)\n",
    "X_train = np.array(train)\n",
    "X_test= np.array(test)\n",
    "#X_train = np.append(X_train,np.reshape(X_train[:,0]*X_train[:,1],(len(X_train),1)),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(cross_val(X_train,np.array(labels), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = ensemble(X_train, np.array(labels), X_test)\n",
    "\n",
    "preds = pd.DataFrame({\"Id\": test_ind, \"Hazard\": y_pred})\n",
    "preds = preds.set_index('Id')\n",
    "preds.to_csv('xgboost_ens_submit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
