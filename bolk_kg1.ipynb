{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from os import listdir,makedirs\n",
    "from os.path import isfile, join,exists,dirname\n",
    "import time\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import ConditionalFreqDist,FreqDist\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import webbrowser\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "import pyximport; pyximport.install()\n",
    "import word_ngrams as w_ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ensure_dir(f):\n",
    "    d = dirname(f)\n",
    "    if not exists(d):\n",
    "        makedirs(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_features(text):\n",
    "    #stemmer = PorterStemmer()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    vec_words = tokenizer.tokenize(text)\n",
    "    #vec_words = map(lambda x:stemmer.stem(x.lower()),tokenizer.tokenize(text))\n",
    "    #vec_words = map(lambda x:x.lower(),tokenizer.tokenize(text))\n",
    "    emma_cfd = FreqDist( w_ng.word_ngarms(vec_words,1)) # число означает длину n-грамм\n",
    "    #emma_cfd = FreqDist(vec_words)\n",
    "    return emma_cfd.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1640.55704403 seconds ---\n",
      "--- 1666.78732395 seconds ---\n",
      "--- 1635.04572701 seconds ---\n",
      "--- 1682.85409403 seconds ---\n",
      "--- 1667.93849802 seconds ---\n",
      "--- 1697.60263896 seconds ---\n"
     ]
    }
   ],
   "source": [
    "for group in [0,1,2,3,4,5]:\n",
    "    mypath = '../data raw/' + str(group) + '/' # разархивированные тексты\n",
    "    onlyfiles = [ f for f in listdir(mypath) if isfile(join(mypath,f)) ]\n",
    "\n",
    "    start_time = time.time()\n",
    "    newpath = '../data raw/features_word_four_' + str(group) + '/'\n",
    "    ensure_dir(newpath)\n",
    "\n",
    "    for filename in onlyfiles:\n",
    "        filename = filename.split('.')[0]\n",
    "\n",
    "\n",
    "        with open(mypath + filename + '.txt') as f:\n",
    "            text = f.read()\n",
    "\n",
    "        with open(newpath + filename, 'w+') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerows(extract_features(text))\n",
    "\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
